# Entropy

Entropy merupakan konsep pengukuran ketidakpastian atau keacakan dalam sebuah variabel random.
Semakin tinggi nilai entropy, semakin tidak pasti nilai variabel random tersebut.

Rumus:

```
H(X) = -âˆ‘p(x)log(p(x))
```

Fungsi [sumber kode [disini](https://github.com/bellshade/OpenSeries/blob/main/OpenSeries/statistika.py#L6)]

```python
def entropy(
  label: list[int], base: int = None
) -> Union[float, int, str]:
```

Contoh Kode

```python
from OpenSeries import statistika as statistika

# contoh dari entropy
label = [1, 1, 2, 2, 3, 3]
hasil_base_2 = statistika.entropy(label, base=2)
print(hasil_base_2)
```

## Coba Sekarang

<iframe src="https://replit.com/@ItsArul/Entropy?embed=1&theme=light" className="aspect-video w-full" />
